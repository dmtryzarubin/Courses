{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Выполните следующие шаги:\n",
    "\n",
    "1) Загрузите выборку Wine по адресу https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data (файл также приложен к этому заданию)\n",
    "2) Извлеките из данных признаки и классы. Класс записан в первом столбце (три варианта), признаки — в столбцах со второго по последний. Более подробно о сути признаков можно прочитать по адресу https://archive.ics.uci.edu/ml/datasets/Wine (см. также файл wine.names, приложенный к заданию)\n",
    "3) Оценку качества необходимо провести методом кросс-валидации по 5 блокам (5-fold). Создайте генератор разбиений, который перемешивает выборку перед формированием блоков (shuffle=True). Для воспроизводимости результата, создавайте генератор KFold с фиксированным параметром random_state=42. В качестве меры качества используйте долю верных ответов (accuracy).\n",
    "Найдите точность классификации на кросс-валидации для метода k ближайших соседей (sklearn.neighbors.KNeighborsClassifier), при k от 1 до 50. При каком k получилось оптимальное качество? Чему оно равно (число в интервале от 0 до 1)? Данные результаты и будут ответами на вопросы 1 и 2.\n",
    "4) Произведите масштабирование признаков с помощью функции sklearn.preprocessing.scale. Снова найдите оптимальное k на кросс-валидации.\n",
    "5) Какое значение k получилось оптимальным после приведения признаков к одному масштабу? Приведите ответы на вопросы 3 и 4. Помогло ли масштабирование признаков?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('wine.data', header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   0      1     2     3     4    5     6     7     8     9     10    11    12  \\\n0   1  14.23  1.71  2.43  15.6  127  2.80  3.06  0.28  2.29  5.64  1.04  3.92   \n1   1  13.20  1.78  2.14  11.2  100  2.65  2.76  0.26  1.28  4.38  1.05  3.40   \n2   1  13.16  2.36  2.67  18.6  101  2.80  3.24  0.30  2.81  5.68  1.03  3.17   \n3   1  14.37  1.95  2.50  16.8  113  3.85  3.49  0.24  2.18  7.80  0.86  3.45   \n4   1  13.24  2.59  2.87  21.0  118  2.80  2.69  0.39  1.82  4.32  1.04  2.93   \n\n     13  \n0  1065  \n1  1050  \n2  1185  \n3  1480  \n4   735  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>10</th>\n      <th>11</th>\n      <th>12</th>\n      <th>13</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>14.23</td>\n      <td>1.71</td>\n      <td>2.43</td>\n      <td>15.6</td>\n      <td>127</td>\n      <td>2.80</td>\n      <td>3.06</td>\n      <td>0.28</td>\n      <td>2.29</td>\n      <td>5.64</td>\n      <td>1.04</td>\n      <td>3.92</td>\n      <td>1065</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>13.20</td>\n      <td>1.78</td>\n      <td>2.14</td>\n      <td>11.2</td>\n      <td>100</td>\n      <td>2.65</td>\n      <td>2.76</td>\n      <td>0.26</td>\n      <td>1.28</td>\n      <td>4.38</td>\n      <td>1.05</td>\n      <td>3.40</td>\n      <td>1050</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>13.16</td>\n      <td>2.36</td>\n      <td>2.67</td>\n      <td>18.6</td>\n      <td>101</td>\n      <td>2.80</td>\n      <td>3.24</td>\n      <td>0.30</td>\n      <td>2.81</td>\n      <td>5.68</td>\n      <td>1.03</td>\n      <td>3.17</td>\n      <td>1185</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>14.37</td>\n      <td>1.95</td>\n      <td>2.50</td>\n      <td>16.8</td>\n      <td>113</td>\n      <td>3.85</td>\n      <td>3.49</td>\n      <td>0.24</td>\n      <td>2.18</td>\n      <td>7.80</td>\n      <td>0.86</td>\n      <td>3.45</td>\n      <td>1480</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>13.24</td>\n      <td>2.59</td>\n      <td>2.87</td>\n      <td>21.0</td>\n      <td>118</td>\n      <td>2.80</td>\n      <td>2.69</td>\n      <td>0.39</td>\n      <td>1.82</td>\n      <td>4.32</td>\n      <td>1.04</td>\n      <td>2.93</td>\n      <td>735</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = data.iloc[:,1:], data.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from statistics import mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits= 5, random_state = 42, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = dict()\n",
    "for k in range(1,51):\n",
    "    scores[k] = 0\n",
    "    clf = KNeighborsClassifier(n_neighbors = k)\n",
    "    clf.fit(X, y)\n",
    "    score = cross_val_score(clf, X, y, cv = kf, scoring=\"accuracy\")\n",
    "    scores[k] = mean(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "1 0.7304761904761905\n34 0.7246031746031746\n35 0.7246031746031746\n48 0.719047619047619\n29 0.7134920634920635\n32 0.7134920634920635\n33 0.7134920634920635\n36 0.7134920634920635\n37 0.7134920634920635\n38 0.7134920634920635\n41 0.7134920634920635\n3 0.7082539682539682\n28 0.707936507936508\n30 0.707936507936508\n39 0.707936507936508\n40 0.7077777777777778\n42 0.7077777777777778\n43 0.7077777777777778\n44 0.7077777777777778\n45 0.7077777777777778\n46 0.7077777777777778\n50 0.7077777777777778\n24 0.7076190476190476\n11 0.7025396825396826\n9 0.7023809523809523\n23 0.7020634920634921\n15 0.7019047619047619\n21 0.7019047619047619\n25 0.7019047619047619\n17 0.7015873015873015\n12 0.6966666666666667\n47 0.6966666666666667\n49 0.6966666666666667\n22 0.6965079365079365\n26 0.6965079365079365\n27 0.6963492063492064\n13 0.690952380952381\n20 0.690952380952381\n31 0.690952380952381\n10 0.6801587301587302\n7 0.68\n8 0.68\n16 0.6795238095238095\n18 0.6795238095238095\n14 0.6793650793650794\n19 0.6793650793650794\n5 0.6746031746031746\n6 0.6742857142857143\n2 0.6625396825396825\n4 0.6577777777777778\n"
    }
   ],
   "source": [
    "sort_scores = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
    "for i in sort_scores:\n",
    "\tprint(i[0], i[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Запись в файл\n",
    "with open('coursera-2.txt', 'w') as ouf:\n",
    "    ouf.write(str(round(float(scores[1]), 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled = scale(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_2 = dict()\n",
    "for k in range(1,51):\n",
    "    scores_2[k] = 0\n",
    "    clf = KNeighborsClassifier(n_neighbors = k)\n",
    "    clf.fit(X_scaled, y)\n",
    "    score = cross_val_score(clf, X_scaled, y, cv = kf, scoring=\"accuracy\")\n",
    "    scores_2[k] = mean(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_scores_2 = sorted(scores_2.items(), key=lambda x: x[1], reverse=True)\n",
    "# отсортируем словарь scores_2, по значениям"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "29 0.9776190476190476\n15 0.9720634920634921\n16 0.9720634920634921\n17 0.9665079365079365\n18 0.9665079365079365\n20 0.9665079365079365\n22 0.9665079365079365\n14 0.9663492063492063\n28 0.9663492063492063\n33 0.9663492063492063\n34 0.9663492063492063\n41 0.9663492063492063\n43 0.9663492063492063\n45 0.9663492063492063\n11 0.9609523809523809\n21 0.9609523809523809\n23 0.9609523809523809\n9 0.9607936507936508\n10 0.9607936507936508\n26 0.9607936507936508\n30 0.9607936507936508\n32 0.9607936507936508\n35 0.9607936507936508\n36 0.9607936507936508\n38 0.9607936507936508\n39 0.9607936507936508\n40 0.9607936507936508\n42 0.9607936507936508\n44 0.9606349206349206\n50 0.9606349206349206\n19 0.9553968253968254\n8 0.9552380952380952\n12 0.9552380952380952\n24 0.9552380952380952\n25 0.9552380952380952\n27 0.9552380952380952\n31 0.9552380952380952\n37 0.9552380952380952\n3 0.9550793650793651\n47 0.9550793650793651\n49 0.9550793650793651\n6 0.9495238095238095\n7 0.9495238095238095\n13 0.9495238095238095\n46 0.9495238095238095\n48 0.9495238095238095\n5 0.9493650793650793\n1 0.9439682539682539\n4 0.9382539682539682\n2 0.9328571428571428\n"
    }
   ],
   "source": [
    "for i in sort_scores_2:\n",
    "\tprint(i[0], i[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# запись в файл\n",
    "with open('coursera-2.txt', 'w') as ouf:\n",
    "    ouf.write(str(round(float(scores_2[29]), 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Выбор метрики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import scale\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from statistics import mean\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_boston"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Загрузите выборку Boston с помощью функции sklearn.datasets.load_boston(). Результатом вызова данной функции является объект, у которого признаки записаны в поле data, а целевой вектор — в поле target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_boston(return_X_y=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Приведите признаки в выборке к одному масштабу при помощи функции sklearn.preprocessing.scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = scale(X)\n",
    "kf = KFold(n_splits= 5, random_state = 42, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Переберите разные варианты параметра метрики p по сетке от 1 до 10 с таким шагом, чтобы всего было протестировано 200 вариантов (используйте функцию numpy.linspace). Используйте KNeighborsRegressor с n_neighbors=5 и weights='distance' — данный параметр добавляет в алгоритм веса, зависящие от расстояния до ближайших соседей. В качестве метрики качества используйте среднеквадратичную ошибку (параметр scoring='mean_squared_error' у cross_val_score; при использовании библиотеки scikit-learn версии 0.18.1 и выше необходимо указывать scoring='neg_mean_squared_error'). Качество оценивайте, как и в предыдущем задании, с помощью кросс-валидации по 5 блокам с random_state = 42, не забудьте включить перемешивание выборки (shuffle=True)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "p:  1.0  accuracy:  -16.030646734221648\np:  1.0452261306532664  accuracy:  -16.407838708329994\np:  1.0904522613065326  accuracy:  -16.370696947059045\np:  1.135678391959799  accuracy:  -16.445716308439437\np:  1.1809045226130652  accuracy:  -16.475057773399403\np:  1.2261306532663316  accuracy:  -16.526432329318265\np:  1.271356783919598  accuracy:  -16.63670934589826\np:  1.3165829145728645  accuracy:  -16.824224254267314\np:  1.3618090452261307  accuracy:  -16.874209056598747\np:  1.4070351758793969  accuracy:  -17.124898819792122\np:  1.4522613065326633  accuracy: -17.145231882153897\np:  1.4974874371859297  accuracy:  -17.01936008026763\np:  1.542713567839196  accuracy:  -17.099131737713773\np:  1.5879396984924623  accuracy:  -16.80132664028837\np:  1.6331658291457287  accuracy:  -16.98074519818978\np:  1.678391959798995  accuracy:  -17.033458903647716\np:  1.7236180904522613  accuracy:  -17.171641902662284\np:  1.7688442211055277  accuracy:  -17.181679169045054\np:  1.814070351758794  accuracy:  -17.208263742870965\np:  1.8592964824120604  accuracy:  -17.323680198398375\np:  1.9045226130653266  accuracy:  -17.415118891722813\np:  1.949748743718593  accuracy:  -17.385662319793237\np:  1.9949748743718594  accuracy:  -17.32603859766246\np:  2.040201005025126  accuracy:  -17.33696697616567\np:  2.085427135678392  accuracy:  -17.382648653849696\np:  2.1306532663316586  accuracy:  -17.656697514148\np:  2.1758793969849246  accuracy:  -17.569894502250555\np:  2.221105527638191  accuracy:  -17.319503281094068\np:  2.2663316582914574  accuracy:  -17.50473249834047\np:  2.3115577889447234  accuracy:  -17.5544941795893\np:  2.35678391959799  accuracy:  -17.566035281733512\np:  2.4020100502512562  accuracy:  -17.596032653116758\np:  2.4472361809045227  accuracy:  -17.599097197501656\np:  2.492462311557789  accuracy:  -17.28225655722672\np:  2.5376884422110555  accuracy:-17.326364532505206\np:  2.582914572864322  accuracy:  -17.48516457265509\np:  2.628140703517588  accuracy:  -17.460236626804758\np:  2.6733668341708543  accuracy:  -17.477436189905525\np:  2.7185929648241207  accuracy:  -17.546167686417423\np:  2.7638190954773867  accuracy:  -17.528053717549938\np:  2.809045226130653  accuracy:  -17.614696329907154\np:  2.8542713567839195  accuracy:  -17.60847148992978\np:  2.899497487437186  accuracy:  -17.650083986804702\np:  2.9447236180904524  accuracy:  -17.889130893742163\np:  2.9899497487437188  accuracy:  -17.885633475989607\np:  3.035175879396985  accuracy:  -18.101862460092264\np:  3.080402010050251  accuracy:  -18.149154780822307\np:  3.1256281407035176  accuracy:  -18.222203209503665\np:  3.170854271356784  accuracy:  -18.27951784014995\np:  3.2160804020100504  accuracy:  -18.28441038485844\np:  3.261306532663317  accuracy:  -18.280842481583775\np:  3.306532663316583  accuracy:  -18.21471509416535\np:  3.351758793969849  accuracy:  -18.515185280995997\np:  3.3969849246231156  accuracy:  -18.471446836958062\np:  3.442211055276382  accuracy:  -18.57545141427405\np:  3.4874371859296485  accuracy:  -18.586865033363807\np:  3.532663316582915  accuracy:  -18.850095290052927\np:  3.577889447236181  accuracy:  -18.8876668848972\np:  3.6231155778894473  accuracy:  -18.93167327700974\np:  3.6683417085427137  accuracy:  -18.93731592618012\np:  3.71356783919598  accuracy:  -18.910467174710746\np:  3.7587939698492465  accuracy:  -18.9132121646769\np:  3.8040201005025125  accuracy:  -19.01464670258458\np:  3.849246231155779  accuracy:  -19.061420855938177\np:  3.8944723618090453  accuracy:  -19.04979117073024\np:  3.9396984924623117  accuracy:  -19.078187723374846\np:  3.984924623115578  accuracy:  -19.16528652866065\np:  4.030150753768844  accuracy:  -19.173754771167346\np:  4.075376884422111  accuracy:  -19.13084222644743\np:  4.1206030150753765  accuracy:  -19.099267941871084\np:  4.165829145728644  accuracy:  -19.124757728626108\np:  4.211055276381909  accuracy:  -19.07301531264819\np:  4.256281407035176  accuracy:  -19.28988816523742\np:  4.301507537688442  accuracy:  -19.299829999167464\np:  4.346733668341709  accuracy:  -19.299315809385767\np:  4.391959798994975  accuracy:  -19.30652577455237\np:  4.437185929648241  accuracy:  -19.211694767941964\np:  4.482412060301508  accuracy:  -19.197623949745598\np:  4.527638190954773  accuracy:  -19.2490636479788\np:  4.572864321608041  accuracy:  -19.407609005575047\np:  4.618090452261306  accuracy:  -19.46858855069072\np:  4.6633165829145735  accuracy:  -19.480380362924432\np:  4.708542713567839  accuracy:  -19.577443558088486\np:  4.7537688442211055  accuracy:  -19.672926079101828\np:  4.798994974874372  accuracy:  -19.684238565030043\np:  4.844221105527638  accuracy:  -19.731419398024357\np:  4.889447236180905  accuracy:  -19.733369104140223\np:  4.934673366834171  accuracy:  -19.738696325445964\np:  4.9798994974874375  accuracy:  -19.769988446644327\np:  5.025125628140704  accuracy:  -19.670338059212803\np: 5.07035175879397  accuracy:  -19.674313935868224\np:  5.115577889447236  accuracy:  -19.632889893449047\np:  5.160804020100502  accuracy:  -19.659695780237264\np:  5.206030150753769  accuracy:  -19.649106525992945\np:  5.251256281407035  accuracy:  -19.67714888621315\np:  5.296482412060302  accuracy:  -19.64968090362701\np:  5.341708542713568  accuracy:  -19.654275491776183\np:  5.386934673366834  accuracy:  -19.682205525268138\np:  5.432160804020101  accuracy:  -19.685318799221015\np:  5.477386934673367  accuracy:  -19.722423366893086\np:  5.522613065326634  accuracy:  -19.884897890673265\np: 5.5678391959799  accuracy:  -19.8630822213311\np:  5.613065326633166  accuracy:  -19.878939440146763\np:  5.658291457286432  accuracy:  -19.906251282633093\np:  5.703517587939698  accuracy:  -19.910320385587003\np:  5.748743718592965  accuracy:  -19.902438102260962\np:  5.793969849246231  accuracy:  -20.112537101843813\np:  5.839195979899498  accuracy:  -20.293191477285607\np:  5.884422110552764  accuracy:  -20.297157861148563\np:  5.9296482412060305  accuracy:  -20.175003396044353\np:  5.974874371859297  accuracy:  -20.121621866892983\np:  6.020100502512563  accuracy:  -20.124990792768504\np:  6.06532663316583  accuracy:  -20.125536942150934\np:  6.110552763819095  accuracy:  -20.07629977697311\np:  6.155778894472362  accuracy:  -20.05124803311445\np:  6.201005025125628  accuracy:  -20.04084957508464\np:  6.2462311557788945  accuracy:  -20.048463589548373\np:  6.291457286432161  accuracy:  -20.054179834596436\np:  6.336683417085427  accuracy:  -20.542085209320764\np:  6.381909547738694  accuracy:  -20.55592419831774\np:  6.42713567839196  accuracy:  -20.558740237646052\np:  6.472361809045227  accuracy:  -20.607239049053742\np:  6.517587939698493  accuracy:  -20.58733687906358\np:  6.562814070351759  accuracy:  -20.598028140441187\np:  6.608040201005025  accuracy:  -20.583967336441393\np:  6.653266331658291  accuracy:  -20.580163334501\np:  6.698492462311558  accuracy:  -20.588575011809407\np:  6.743718592964824  accuracy:  -20.603890564541306\np:  6.788944723618091  accuracy:  -20.604907409925623\np:  6.834170854271357  accuracy:  -20.60255496042737\np:  6.8793969849246235  accuracy:  -20.605204358288454\np:  6.92462311557789  accuracy:  -20.607526973699624\np:  6.969849246231156  accuracy:  -20.6523836464863\np:  7.015075376884423  accuracy:  -20.671602667947084\np:  7.060301507537688  accuracy:  -20.687580712184765\np:  7.105527638190955  accuracy:  -20.69126542796107\np:  7.150753768844221  accuracy:  -20.677962354617563\np:  7.1959798994974875  accuracy:  -20.680109742003737\np:  7.241206030150754  accuracy:  -20.879258126322675\np:  7.28643216080402  accuracy:  -20.978689847496778\np:  7.331658291457287  accuracy:  -20.993715767097477\np:  7.376884422110553  accuracy:  -20.995591100386992\np:  7.42211055276382  accuracy:  -21.00948881592416\np:  7.467336683417086  accuracy:  -21.011300377670636\np:  7.5125628140703515  accuracy:  -21.013081934167804\np:  7.557788944723618  accuracy:  -21.0148340985596\np:  7.603015075376884  accuracy:  -21.017417638850493\np:  7.648241206030151  accuracy:  -21.010864960901042\np:  7.693467336683417  accuracy:  -21.029703207238985\np:  7.738693467336684  accuracy:  -21.02242241833668\np:  7.78391959798995  accuracy:  -21.024029046962752\np:  7.8291457286432165  accuracy:  -21.05785349464953\np:  7.874371859296483  accuracy:  -21.0656423085044\np:  7.919597989949749  accuracy:  -21.06698490725231\np:  7.964824120603016  accuracy:  -21.068482443357823\np:  8.010050251256281  accuracy:  -21.068183279830645\np:  8.055276381909547  accuracy:  -21.071034728064934\np:  8.100502512562814  accuracy:  -21.02558771191022\np:  8.145728643216081  accuracy:  -20.95110250575009\np:  8.190954773869347  accuracy:  -20.996152778095713\np:  8.236180904522612  accuracy:  -20.89273181656232\np:  8.28140703517588  accuracy:  -20.894066896730617\np:  8.326633165829147  accuracy:  -21.007724663240943\np:  8.371859296482413  accuracy:  -21.009025299728833\np:  8.417085427135678  accuracy:  -21.01216221477924\np:  8.462311557788945  accuracy:  -21.01710510789646\np:  8.507537688442211  accuracy:  -21.01498302189046\np:  8.552763819095478  accuracy:  -21.016208031732354\np:  8.597989949748744  accuracy:  -21.012396399713907\np:  8.64321608040201  accuracy:  -21.013034449348478\np:  8.688442211055277  accuracy:  -21.016253998579874\np:  8.733668341708544  accuracy:  -21.006107338225995\np:  8.77889447236181  accuracy:  -21.005785678059887\np:  8.824120603015075  accuracy:  -21.007206235081096\np:  8.869346733668342  accuracy:  -21.0041469184321\np:  8.91457286432161  accuracy:  -21.00717088901068\np:  8.959798994974875  accuracy:  -21.008262762424195\np:  9.00502512562814  accuracy:  -21.01810166737625\np:  9.050251256281408  accuracy:  -21.019162230863916\np:  9.095477386934673  accuracy:  -21.083360868317154\np:  9.14070351758794  accuracy:  -21.07746579657623\np:  9.185929648241206  accuracy:  -21.07851707608195\np:  9.231155778894472  accuracy:  -21.079037165101987\np:  9.27638190954774  accuracy:  -21.080059124071415\np:  9.321608040201005  accuracy:  -21.104978219205865\np:  9.366834170854272  accuracy:  -21.1058426886423\np:  9.412060301507537  accuracy:  -21.110567605644725\np:  9.457286432160805  accuracy:  -21.111525199609268\np:  9.50251256281407  accuracy:  -21.112469472718395\np:  9.547738693467338  accuracy:  -21.06615486341529\np:  9.592964824120603  accuracy:  -21.06651176724178\np:  9.63819095477387  accuracy:  -21.07481429835116\np:  9.683417085427136  accuracy:  -21.075721076535178\np:  9.728643216080402  accuracy:  -21.07661546615345\np:  9.773869346733669  accuracy:  -21.07749767601852\np:  9.819095477386934  accuracy:  -21.08126399272046\np:  9.864321608040202  accuracy:  -21.08212737263425\np:  9.909547738693467  accuracy:  -21.082979124590295\np:  9.954773869346734  accuracy:  -21.08381944188997\np:  10.0  accuracy:  -21.089703307229723\n"
    }
   ],
   "source": [
    "a = np.linspace(1,10, num = 200)\n",
    "scores = dict()\n",
    "for p in a:\n",
    "    scores[p]=[]\n",
    "    clf = KNeighborsRegressor(n_neighbors = 5, weights='distance', metric = 'minkowski', p = p)\n",
    "    clf.fit(X, y)\n",
    "    score = cross_val_score(clf, X, y, cv = kf, scoring=\"neg_mean_squared_error\")\n",
    "    scores[p].append(mean(score))\n",
    "    print('p: ',p, ' accuracy: ', mean(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Определите, при каком p качество на кросс-валидации оказалось оптимальным. Обратите внимание, что cross_val_score возвращает массив показателей качества по блокам; необходимо максимизировать среднее этих показателей. Это значение параметра и будет ответом на задачу."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "1.0 [-16.030646734221648]\n1.0904522613065326 [-16.370696947059045]\n1.0452261306532664 [-16.407838708329994]\n1.135678391959799 [-16.445716308439437]\n1.1809045226130652 [-16.475057773399403]\n1.2261306532663316 [-16.526432329318265]\n1.271356783919598 [-16.63670934589826]\n1.5879396984924623 [-16.80132664028837]\n1.3165829145728645 [-16.824224254267314]\n1.3618090452261307 [-16.874209056598747]\n1.6331658291457287 [-16.98074519818978]\n1.4974874371859297 [-17.01936008026763]\n1.678391959798995 [-17.033458903647716]\n1.542713567839196 [-17.099131737713773]\n1.4070351758793969 [-17.124898819792122]\n1.4522613065326633 [-17.145231882153897]\n1.7236180904522613 [-17.171641902662284]\n1.7688442211055277 [-17.181679169045054]\n1.814070351758794 [-17.208263742870965]\n2.492462311557789 [-17.28225655722672]\n2.221105527638191 [-17.319503281094068]\n1.8592964824120604 [-17.323680198398375]\n1.9949748743718594 [-17.32603859766246]\n2.5376884422110555 [-17.326364532505206]\n2.040201005025126 [-17.33696697616567]\n2.085427135678392 [-17.382648653849696]\n1.949748743718593 [-17.385662319793237]\n1.9045226130653266 [-17.415118891722813]\n2.628140703517588 [-17.460236626804758]\n2.6733668341708543 [-17.477436189905525]\n2.582914572864322 [-17.48516457265509]\n2.2663316582914574 [-17.50473249834047]\n2.7638190954773867 [-17.528053717549938]\n2.7185929648241207 [-17.546167686417423]\n2.3115577889447234 [-17.5544941795893]\n2.35678391959799 [-17.566035281733512]\n2.1758793969849246 [-17.569894502250555]\n2.4020100502512562 [-17.596032653116758]\n2.4472361809045227 [-17.599097197501656]\n2.8542713567839195 [-17.60847148992978]\n2.809045226130653 [-17.614696329907154]\n2.899497487437186 [-17.650083986804702]\n2.1306532663316586 [-17.656697514148]\n2.9899497487437188 [-17.885633475989607]\n2.9447236180904524 [-17.889130893742163]\n3.035175879396985 [-18.101862460092264]\n3.080402010050251 [-18.149154780822307]\n3.306532663316583 [-18.21471509416535]\n3.1256281407035176 [-18.222203209503665]\n3.170854271356784 [-18.27951784014995]\n3.261306532663317 [-18.280842481583775]\n3.2160804020100504 [-18.28441038485844]\n3.3969849246231156 [-18.471446836958062]\n3.351758793969849 [-18.515185280995997]\n3.442211055276382 [-18.57545141427405]\n3.4874371859296485 [-18.586865033363807]\n3.532663316582915 [-18.850095290052927]\n3.577889447236181 [-18.8876668848972]\n3.71356783919598 [-18.910467174710746]\n3.7587939698492465 [-18.9132121646769]\n3.6231155778894473 [-18.93167327700974]\n3.6683417085427137 [-18.93731592618012]\n3.8040201005025125 [-19.01464670258458]\n3.8944723618090453 [-19.04979117073024]\n3.849246231155779 [-19.061420855938177]\n4.211055276381909 [-19.07301531264819]\n3.9396984924623117 [-19.078187723374846]\n4.1206030150753765 [-19.099267941871084]\n4.165829145728644 [-19.124757728626108]\n4.075376884422111 [-19.13084222644743]\n3.984924623115578 [-19.16528652866065]\n4.030150753768844 [-19.173754771167346]\n4.482412060301508 [-19.197623949745598]\n4.437185929648241 [-19.211694767941964]\n4.527638190954773 [-19.2490636479788]\n4.256281407035176 [-19.28988816523742]\n4.346733668341709 [-19.299315809385767]\n4.301507537688442 [-19.299829999167464]\n4.391959798994975 [-19.30652577455237]\n4.572864321608041 [-19.407609005575047]\n4.618090452261306 [-19.46858855069072]\n4.6633165829145735 [-19.480380362924432]\n4.708542713567839 [-19.577443558088486]\n5.115577889447236 [-19.632889893449047]\n5.206030150753769 [-19.649106525992945]\n5.296482412060302 [-19.64968090362701]\n5.341708542713568 [-19.654275491776183]\n5.160804020100502 [-19.659695780237264]\n5.025125628140704 [-19.670338059212803]\n4.7537688442211055 [-19.672926079101828]\n5.07035175879397 [-19.674313935868224]\n5.251256281407035 [-19.67714888621315]\n5.386934673366834 [-19.682205525268138]\n4.798994974874372 [-19.684238565030043]\n5.432160804020101 [-19.685318799221015]\n5.477386934673367 [-19.722423366893086]\n4.844221105527638 [-19.731419398024357]\n4.889447236180905 [-19.733369104140223]\n4.934673366834171 [-19.738696325445964]\n4.9798994974874375 [-19.769988446644327]\n5.5678391959799 [-19.8630822213311]\n5.613065326633166 [-19.878939440146763]\n5.522613065326634 [-19.884897890673265]\n5.748743718592965 [-19.902438102260962]\n5.658291457286432 [-19.906251282633093]\n5.703517587939698 [-19.910320385587003]\n6.201005025125628 [-20.04084957508464]\n6.2462311557788945 [-20.048463589548373]\n6.155778894472362 [-20.05124803311445]\n6.291457286432161 [-20.054179834596436]\n6.110552763819095 [-20.07629977697311]\n5.793969849246231 [-20.112537101843813]\n5.974874371859297 [-20.121621866892983]\n6.020100502512563 [-20.124990792768504]\n6.06532663316583 [-20.125536942150934]\n5.9296482412060305 [-20.175003396044353]\n5.839195979899498 [-20.293191477285607]\n5.884422110552764 [-20.297157861148563]\n6.336683417085427 [-20.542085209320764]\n6.381909547738694 [-20.55592419831774]\n6.42713567839196 [-20.558740237646052]\n6.653266331658291 [-20.580163334501]\n6.608040201005025 [-20.583967336441393]\n6.517587939698493 [-20.58733687906358]\n6.698492462311558 [-20.588575011809407]\n6.562814070351759 [-20.598028140441187]\n6.834170854271357 [-20.60255496042737]\n6.743718592964824 [-20.603890564541306]\n6.788944723618091 [-20.604907409925623]\n6.8793969849246235 [-20.605204358288454]\n6.472361809045227 [-20.607239049053742]\n6.92462311557789 [-20.607526973699624]\n6.969849246231156 [-20.6523836464863]\n7.015075376884423 [-20.671602667947084]\n7.150753768844221 [-20.677962354617563]\n7.1959798994974875 [-20.680109742003737]\n7.060301507537688 [-20.687580712184765]\n7.105527638190955 [-20.69126542796107]\n7.241206030150754 [-20.879258126322675]\n8.236180904522612 [-20.89273181656232]\n8.28140703517588 [-20.894066896730617]\n8.145728643216081 [-20.95110250575009]\n7.28643216080402 [-20.978689847496778]\n7.331658291457287 [-20.993715767097477]\n7.376884422110553 [-20.995591100386992]\n8.190954773869347 [-20.996152778095713]\n8.869346733668342 [-21.0041469184321]\n8.77889447236181 [-21.005785678059887]\n8.733668341708544 [-21.006107338225995]\n8.91457286432161 [-21.00717088901068]\n8.824120603015075 [-21.007206235081096]\n8.326633165829147 [-21.007724663240943]\n8.959798994974875 [-21.008262762424195]\n8.371859296482413 [-21.009025299728833]\n7.42211055276382 [-21.00948881592416]\n7.648241206030151 [-21.010864960901042]\n7.467336683417086 [-21.011300377670636]\n8.417085427135678 [-21.01216221477924]\n8.597989949748744 [-21.012396399713907]\n8.64321608040201 [-21.013034449348478]\n7.5125628140703515 [-21.013081934167804]\n7.557788944723618 [-21.0148340985596]\n8.507537688442211 [-21.01498302189046]\n8.552763819095478 [-21.016208031732354]\n8.688442211055277 [-21.016253998579874]\n8.462311557788945 [-21.01710510789646]\n7.603015075376884 [-21.017417638850493]\n9.00502512562814 [-21.01810166737625]\n9.050251256281408 [-21.019162230863916]\n7.738693467336684 [-21.02242241833668]\n7.78391959798995 [-21.024029046962752]\n8.100502512562814 [-21.02558771191022]\n7.693467336683417 [-21.029703207238985]\n7.8291457286432165 [-21.05785349464953]\n7.874371859296483 [-21.0656423085044]\n9.547738693467338 [-21.06615486341529]\n9.592964824120603 [-21.06651176724178]\n7.919597989949749 [-21.06698490725231]\n8.010050251256281 [-21.068183279830645]\n7.964824120603016 [-21.068482443357823]\n8.055276381909547 [-21.071034728064934]\n9.63819095477387 [-21.07481429835116]\n9.683417085427136 [-21.075721076535178]\n9.728643216080402 [-21.07661546615345]\n9.14070351758794 [-21.07746579657623]\n9.773869346733669 [-21.07749767601852]\n9.185929648241206 [-21.07851707608195]\n9.231155778894472 [-21.079037165101987]\n9.27638190954774 [-21.080059124071415]\n9.819095477386934 [-21.08126399272046]\n9.864321608040202 [-21.08212737263425]\n9.909547738693467 [-21.082979124590295]\n9.095477386934673 [-21.083360868317154]\n9.954773869346734 [-21.08381944188997]\n10.0 [-21.089703307229723]\n9.321608040201005 [-21.104978219205865]\n9.366834170854272 [-21.1058426886423]\n9.412060301507537 [-21.110567605644725]\n9.457286432160805 [-21.111525199609268]\n9.50251256281407 [-21.112469472718395]\n"
    }
   ],
   "source": [
    "sort = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
    "for i in sort:\n",
    "\tprint(i[0], i[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Нормализация признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Загрузите обучающую и тестовую выборки из файлов perceptron-train.csv и perceptron-test.csv. Целевая переменная записана в первом столбце, признаки — во втором и третьем."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv', header = None)\n",
    "test = pd.read_csv('test.csv', header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "     0         1            2\n0 -1.0 -0.024626  1174.600238\n1  1.0 -0.978058  1083.198803\n2 -1.0  0.314272 -1472.977609\n3 -1.0  0.179752   231.017267\n4  1.0 -1.262544  -778.271726",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-1.0</td>\n      <td>-0.024626</td>\n      <td>1174.600238</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.0</td>\n      <td>-0.978058</td>\n      <td>1083.198803</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-1.0</td>\n      <td>0.314272</td>\n      <td>-1472.977609</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-1.0</td>\n      <td>0.179752</td>\n      <td>231.017267</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.0</td>\n      <td>-1.262544</td>\n      <td>-778.271726</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 42
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.iloc[:, 1:]\n",
    "y = train.iloc[:,0]\n",
    "X_t = test.iloc[:, 1:]\n",
    "y_t = test.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Обучите персептрон со стандартными параметрами и random_state=241."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = Perceptron()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Perceptron(alpha=0.0001, class_weight=None, early_stopping=False, eta0=1.0,\n           fit_intercept=True, max_iter=1000, n_iter_no_change=5, n_jobs=None,\n           penalty=None, random_state=0, shuffle=True, tol=0.001,\n           validation_fraction=0.1, verbose=0, warm_start=False)"
     },
     "metadata": {},
     "execution_count": 83
    }
   ],
   "source": [
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Подсчитайте качество (долю правильно классифицированных объектов, accuracy) полученного классификатора на тестовой выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = clf.predict(X_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "accuracy = sklearn.metrics.accuracy_score(y_t, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.655"
     },
     "metadata": {},
     "execution_count": 86
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Нормализуйте обучающую и тестовую выборку с помощью класса StandardScaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X)\n",
    "X_test_scaled = scaler.transform(X_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) Обучите персептрон на новой выборке. Найдите долю правильных ответов на тестовой выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Perceptron(alpha=0.0001, class_weight=None, early_stopping=False, eta0=1.0,\n           fit_intercept=True, max_iter=1000, n_iter_no_change=5, n_jobs=None,\n           penalty=None, random_state=0, shuffle=True, tol=0.001,\n           validation_fraction=0.1, verbose=0, warm_start=False)"
     },
     "metadata": {},
     "execution_count": 88
    }
   ],
   "source": [
    "clf.fit(X_train_scaled, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds2 = clf.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.845"
     },
     "metadata": {},
     "execution_count": 90
    }
   ],
   "source": [
    "accuracy2 = sklearn.metrics.accuracy_score(y_t, preds2)\n",
    "accuracy2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6) Найдите разность между качеством на тестовой выборке после нормализации и качеством до нее. Это число и будет ответом на задание."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.19"
     },
     "metadata": {},
     "execution_count": 92
    }
   ],
   "source": [
    "a = accuracy2 - accuracy\n",
    "round(a,3)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37764bittensorflowcondaae9ae9f78a3b4da8b90f6c6ad082f906",
   "display_name": "Python 3.7.7 64-bit ('tensorflow': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}